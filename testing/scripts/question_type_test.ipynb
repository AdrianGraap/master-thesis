{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../results/question_type.csv', index_col=0)\n",
    "\n",
    "# df['question_type'].loc[df['question_type']=='factoid'] = 1.0\n",
    "# df['question_type'].loc[df['question_type']=='boolean'] = 2.0\n",
    "# df['question_type'].loc[df['question_type']=='count'] = 3.0\n",
    "# df['question_type'].loc[df['question_type']=='list'] = 4.0\n",
    "\n",
    "# df['question'] = df['question'].apply(lambda x: ' '.join(x.split(' ')[0:4]))\n",
    "df['question'] = df['question'].apply(lambda x: ' '.join(x.split(' ')))\n",
    "df[df['question_type']=='list']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "# vectorizer = HashingVectorizer(lowercase=False)\n",
    "# vectorizer = TfidfVectorizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "questions = df['question']\n",
    "# y = df['question_type'].astype('int')\n",
    "y = df['question_type']\n",
    "\n",
    "questions_train, questions_test, y_train, y_test = train_test_split( questions, y, test_size=0.25, random_state=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer.fit(questions_train)\n",
    "X_train = vectorizer.transform(questions_train)\n",
    "X_test  = vectorizer.transform(questions_test)\n",
    "\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_count(question):\n",
    "    count_list = ['count']\n",
    "    if 'how many' in question.lower():\n",
    "        return True\n",
    "    if question.lower().split(' ')[0] in count_list:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_boolean(question):\n",
    "    bool_list = ['was', 'is', 'are', 'does', 'did']\n",
    "    q_list = question.lower().split(' ')\n",
    "    return q_list[0] in bool_list\n",
    "\n",
    "\n",
    "def check_factoid(question):\n",
    "    word_list = ['what', 'when', 'which', 'who', 'how', 'where', 'whom', 'whose', 'why']\n",
    "    return (question.split(' ')[0].lower() in word_list) or (question.split(' ')[1].lower() in word_list)\n",
    "\n",
    "\n",
    "def check_list(question):\n",
    "    list_list = ['give me', 'name', 'list', 'tell me',  ]\n",
    "    q_list = question.lower().split(' ')\n",
    "    q = ' '.join(q_list)\n",
    "    if q_list[0] in list_list:\n",
    "        return True\n",
    "    if ' '.join(q_list[0:2]) in list_list:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_quest(quest):\n",
    "    if check_count(quest):\n",
    "        return 'count'\n",
    "    elif check_boolean(quest):\n",
    "        return 'boolean'\n",
    "    elif check_factoid(quest):\n",
    "        return 'factoid'\n",
    "    elif check_list(quest):\n",
    "        return 'list'\n",
    "    else:\n",
    "        return ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['approx_question_type'] = df['question'].apply(lambda x: check_quest(x))\n",
    "\n",
    "df['equal'] = df.apply(lambda x: 1 if x['question_type'] == x['approx_question_type'] else 0, axis=1)\n",
    "df['equal'][df['approx_question_type']!=''].mean()\n",
    "# df[df['approx_question_type']=='']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_rest = df[df['approx_question_type']=='']\n",
    "df_rest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_rest = vectorizer.transform(df_rest['question'])\n",
    "\n",
    "score_rest = classifier.score(X_rest, df_rest['question_type'])\n",
    "\n",
    "print(\"Accuracy:\", score_rest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.predict(X_rest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['approx_question_type'] = df.apply(lambda x: classifier.predict(vectorizer.transform([x['question']]))[0] if x['approx_question_type'] == '' else x['approx_question_type'], axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['equal'] = df.apply(lambda x: 1 if x['question_type'] == x['approx_question_type'] else 0, axis=1)\n",
    "df['equal'][df['approx_question_type']!=''].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}